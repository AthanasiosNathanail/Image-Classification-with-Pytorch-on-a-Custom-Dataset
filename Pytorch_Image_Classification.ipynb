{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aerial-proposal",
   "metadata": {},
   "source": [
    "# Section 1 - Dataset Setup and Conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from glob import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Data science tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Image manipulations\n",
    "from PIL import Image\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image path. \n",
    "# Note: the image path should be the same folder for both the jupyter notebook and images folder\n",
    "ImagePATH = f\"Images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the image path\n",
    "ImagePATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = glob(ImagePATH+\"*\")\n",
    "#Check the categories of the available images\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "filedf = pd.DataFrame()\n",
    "for cat in categories:\n",
    "    files = glob(cat+\"/*\")\n",
    "    tempdf = pd.DataFrame({'filepath':files,'category':cat.split(\"/\")[-1]})\n",
    "    filedf = pd.concat([filedf,tempdf])\n",
    "    \n",
    "filedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "gby_cnt = filedf.groupby(\"category\").aggregate('count').rename(columns = {'filepath':'cnt'}).reset_index().sort_values(by='cnt',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a bar chart with the count of images per class\n",
    "px.bar(gby_cnt,x = 'category',y = 'cnt',color = 'category',title = 'Counts from Each Category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir outputs\n",
    "gby_cnt.to_csv(f\"outputs/category_counts.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-nature",
   "metadata": {},
   "source": [
    "# Check some images from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100, 100))\n",
    "\n",
    "for i in range(16):\n",
    "    path = filedf.sample(1)['filepath'].values[0]\n",
    "    category = path.split(\"/\")[0]\n",
    "    ex_img = Image.open(path)\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    ax.annotate(category, xy=(0.65, 0.9), xycoords=\"axes fraction\",weight='bold',size=20)\n",
    "    ax.imshow(ex_img)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_cats = gby_cnt[gby_cnt['cnt'] >=2]['category'].values\n",
    "filedf  = filedf[filedf['category'].isin(focus_cats)]\n",
    "# count the number of images per class in the dataset\n",
    "filedf.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset in traning and testing sets (validation optional)\n",
    "X_train, X_test, _, _ = train_test_split(\n",
    "        filedf, filedf['category'],stratify=filedf['category'], test_size=0.4)\n",
    "\n",
    "X_test, X_val, _, _ = train_test_split(\n",
    "        X_test, X_test['category'], stratify=X_test['category'], test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['type'] = 'train'\n",
    "X_val['type'] = 'val'\n",
    "X_test['type'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf = pd.concat([X_train,X_test])\n",
    "fulldf = pd.concat([X_train,X_test,X_val])    #add X_val if you have a validation folder\n",
    "fulldf.type.value_counts()\n",
    "# Print the count of images for train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-heather",
   "metadata": {},
   "source": [
    "# Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf.category.value_counts()[0]/len(fulldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-liechtenstein",
   "metadata": {},
   "source": [
    "# Creating Data directory: train val test folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-november",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run the following to generate the folders for train, test and validation (optional). Uncomment the commented lines to generate validation folder\n",
    "!mkdir data\n",
    "# !rm -rf data/\n",
    "# !rm -rf data/train\n",
    "# !rm -rf data/test\n",
    "# !rm -rf data/val\n",
    "# !mkdir data/\n",
    "!mkdir data\\train\n",
    "!mkdir data\\test\n",
    "!mkdir data\\val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in fulldf.category.unique():\n",
    "    os.system(f\"mkdir data/train/'{cat}'\") \n",
    "    os.system(f\"mkdir data/test/'{cat}'\") \n",
    "    os.system(f\"mkdir data/val/'{cat}'\")\n",
    "    \n",
    "fulldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in fulldf.iterrows():\n",
    "    # Boat category\n",
    "    cat = row['category']\n",
    "    # section is train,val or test\n",
    "    section = row['type']\n",
    "    # input filepath to copy\n",
    "    ipath = row['filepath']\n",
    "    # output filepath to paste\n",
    "    opath = ipath.replace(f\"images/\",f\"data/{section}/\")\n",
    "    # running the cp command\n",
    "    os.system(f\"cp '{ipath}' '{opath}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-modeling",
   "metadata": {},
   "source": [
    "# Section 2 - Loading and Preparing the Dataset for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "#from torchsummary import summary\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch\n",
    "from torch import optim, cuda\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "import torch.nn as nn\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Data science tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Image manipulations\n",
    "from PIL import Image\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor, nn\n",
    "from torch.nn.functional import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_tensor(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    # Set the color channel as the third dimension\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    # Reverse the preprocessing steps\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "\n",
    "    # Clip the image pixel values\n",
    "    image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    plt.axis('off')\n",
    "\n",
    "    return ax, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindir = f\"data/train\"\n",
    "validdir = f\"data/val\"\n",
    "testdir = f\"data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if you have a GPU and cuda package available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root = traindir, \n",
    "                                  transform = transforms.ToTensor())\n",
    "\n",
    "means = torch.zeros(3)\n",
    "stds = torch.zeros(3)\n",
    "\n",
    "for img, label in train_data:\n",
    "    means += torch.mean(img, dim = (1,2))\n",
    "    stds += torch.std(img, dim = (1,2))\n",
    "\n",
    "means /= len(train_data)\n",
    "stds /= len(train_data)\n",
    "    \n",
    "print(f'Calculated means: {means}')\n",
    "print(f'Calculated stds: {stds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_name = f'resnet50-transfer.pt'\n",
    "checkpoint_path = f'resnet50-transfer.pth'\n",
    "\n",
    "# Change to fit hardware\n",
    "batch_size = 16\n",
    "\n",
    "# Whether to train on a gpu\n",
    "train_on_gpu = cuda.is_available()\n",
    "print(f'Train on gpu: {train_on_gpu}')\n",
    "\n",
    "# Number of gpus\n",
    "if train_on_gpu:\n",
    "    gpu_count = cuda.device_count()\n",
    "    print(f'{gpu_count} gpus detected.')\n",
    "    if gpu_count > 1:\n",
    "        multi_gpu = True\n",
    "    else:\n",
    "        multi_gpu = False\n",
    "print(train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-abortion",
   "metadata": {},
   "source": [
    "# Define Transforms/Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transformations\n",
    "image_transforms = {\n",
    "    # Train uses data augmentation\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),  # Image net standards\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "    ]),\n",
    "    # Validation does not use augmentation\n",
    "    'valid':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "        # Test does not use augmentation\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the result of the data augmentation\n",
    "ex_img = Image.open('C:/your path to an image/image_name.jpg').convert('RGB')\n",
    "#Change the path to one that leads to an image i want to display and apply the transformation\n",
    "t = image_transforms['train']\n",
    "plt.figure(figsize=(24, 24))\n",
    "\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    _ = imshow_tensor(t(ex_img), ax=ax)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-injection",
   "metadata": {},
   "source": [
    "# Define DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-proportion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets from folders\n",
    "data = {\n",
    "    'train':\n",
    "    datasets.ImageFolder(root=traindir, transform=image_transforms['train']),\n",
    "    'valid':\n",
    "    datasets.ImageFolder(root=validdir, transform=image_transforms['valid']),\n",
    "    'test':\n",
    "    datasets.ImageFolder(root=testdir, transform=image_transforms['test'])\n",
    "}\n",
    "\n",
    "# Dataloader iterators, make sure to shuffle\n",
    "dataloaders = {\n",
    "    'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True,num_workers=2),\n",
    "    'val': DataLoader(data['valid'], batch_size=batch_size, shuffle=True,num_workers=2),\n",
    "    'test': DataLoader(data['test'], batch_size=batch_size, shuffle=True,num_workers=2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dataloader once\n",
    "trainiter = iter(dataloaders['train'])\n",
    "features, labels = next(trainiter)\n",
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "for d in os.listdir(traindir):\n",
    "    categories.append(d)\n",
    "    \n",
    "n_classes = len(categories)\n",
    "print(f'There are {n_classes} different classes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-topic",
   "metadata": {},
   "source": [
    "# Statistics to get an idea of the dataset count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = data['train'].class_to_idx\n",
    "idx_to_class = {\n",
    "    idx: class_\n",
    "    for class_, idx in data['train'].class_to_idx.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cnts = Counter([idx_to_class[x] for x in data['train'].targets])\n",
    "val_cnts = Counter([idx_to_class[x] for x in data['valid'].targets])\n",
    "test_cnts = Counter([idx_to_class[x] for x in data['test'].targets])\n",
    "\n",
    "train_cnts = pd.DataFrame({'cat' :list(train_cnts.keys()), 'train_cnt': list(train_cnts.values())})\n",
    "val_cnts = pd.DataFrame({'cat' :list(val_cnts.keys()), 'val_cnt': list(val_cnts.values())})\n",
    "test_cnts = pd.DataFrame({'cat' :list(test_cnts.keys()), 'test_cnt': list(test_cnts.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_df = pd.merge(train_cnts,val_cnts,on='cat',how='left').merge(test_cnts,on='cat',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-diving",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-street",
   "metadata": {},
   "source": [
    "# Section 3 - Building the Image Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the pretrained resnet50 model\n",
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze model weights\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise the model and all the hyperparameters\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Sequential(\n",
    "                      nn.Linear(n_inputs, 256), \n",
    "                      nn.ReLU(), \n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(256, n_classes),                   \n",
    "                      nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-dynamics",
   "metadata": {},
   "source": [
    "# Use CPU or GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    ##Pick GPU if available##\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "device= get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_on_gpu:\n",
    "    model = model.to('cuda')\n",
    "\n",
    "if multi_gpu:\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "if multi_gpu:\n",
    "    print(model.module.fc)\n",
    "else:\n",
    "    print(model.fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-campus",
   "metadata": {},
   "source": [
    "# Model Training (Pytorch model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-engagement",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.class_to_idx = data['train'].class_to_idx\n",
    "model.idx_to_class = {\n",
    "    idx: class_\n",
    "    for class_, idx in model.class_to_idx.items()\n",
    "}\n",
    "\n",
    "list(model.idx_to_class.items())[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the optimiser\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# can also add the learning rate\n",
    "\n",
    "for p in optimizer.param_groups[0]['params']:\n",
    "    if p.requires_grad:\n",
    "        print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          criterion,\n",
    "          optimizer,\n",
    "          train_loader,\n",
    "          valid_loader,\n",
    "          save_file_name,\n",
    "          max_epochs_stop=15,\n",
    "          n_epochs=500,\n",
    "          print_every=5):\n",
    "    \"\"\"Train a PyTorch Model\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        model (PyTorch model): cnn to train\n",
    "        criterion (PyTorch loss): objective to minimize\n",
    "        optimizer (PyTorch optimizier): optimizer to compute gradients of model parameters\n",
    "        train_loader (PyTorch dataloader): training dataloader to iterate through\n",
    "        valid_loader (PyTorch dataloader): validation dataloader used for early stopping\n",
    "        save_file_name (str ending in '.pt'): file path to save the model state dict\n",
    "        max_epochs_stop (int): maximum number of epochs with no improvement in validation loss for early stopping\n",
    "        n_epochs (int): maximum number of training epochs\n",
    "        print_every (int): frequency of epochs to print training stats\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        model (PyTorch model): trained cnn with best weights\n",
    "        history (DataFrame): history of train and validation loss and accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    # Early stopping intialization\n",
    "    epochs_no_improve = 0\n",
    "    valid_loss_min = np.Inf\n",
    "\n",
    "    valid_max_acc = 0\n",
    "    history = []\n",
    "\n",
    "    # Number of epochs already trained (if using loaded in model weights)\n",
    "    try:\n",
    "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
    "    except:\n",
    "        model.epochs = 0\n",
    "        print(f'Starting Training from Scratch.\\n')\n",
    "\n",
    "    overall_start = timer()\n",
    "\n",
    "    # Main loop\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # keep track of training and validation loss each epoch\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_acc = 0\n",
    "        valid_acc = 0\n",
    "\n",
    "        # Set to training\n",
    "        model.train()\n",
    "        start = timer()\n",
    "\n",
    "        # Training loop\n",
    "        for ii, (data, target) in enumerate(train_loader):\n",
    "            # Tensors to gpu\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Predicted outputs are log probabilities\n",
    "            output = model(data)\n",
    "\n",
    "            # Loss and backpropagation of gradients\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track train loss by multiplying average loss by number of examples in batch\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "\n",
    "            # Calculate accuracy by finding max log probability\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "            # Need to convert correct tensor from int to float to average\n",
    "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "            # Multiply average accuracy times the number of examples in batch\n",
    "            train_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "            # Track training progress\n",
    "            print(\n",
    "                f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n",
    "                end='\\r')\n",
    "\n",
    "        # After training loops ends, start validation\n",
    "        else:\n",
    "            model.epochs += 1\n",
    "\n",
    "            # Don't need to keep track of gradients\n",
    "            with torch.no_grad():\n",
    "                # Set to evaluation mode\n",
    "                model.eval()\n",
    "\n",
    "                # Validation loop\n",
    "                for data, target in valid_loader:\n",
    "                    # Tensors to gpu\n",
    "                    if train_on_gpu:\n",
    "                        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                    # Forward pass\n",
    "                    output = model(data)\n",
    "\n",
    "                    # Validation loss\n",
    "                    loss = criterion(output, target)\n",
    "                    # Multiply average loss times the number of examples in batch\n",
    "                    valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                    # Calculate validation accuracy\n",
    "                    _, pred = torch.max(output, dim=1)\n",
    "                    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "                    accuracy = torch.mean(\n",
    "                        correct_tensor.type(torch.FloatTensor))\n",
    "                    # Multiply average accuracy times the number of examples\n",
    "                    valid_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "                # Calculate average losses\n",
    "                train_loss = train_loss / len(train_loader.dataset)\n",
    "                valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "\n",
    "                # Calculate average accuracy\n",
    "                train_acc = train_acc / len(train_loader.dataset)\n",
    "                valid_acc = valid_acc / len(valid_loader.dataset)\n",
    "\n",
    "                history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
    "\n",
    "                # Print training and validation results\n",
    "                if (epoch + 1) % print_every == 0:\n",
    "                    print(\n",
    "                        f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n",
    "                    )\n",
    "                    print(\n",
    "                        f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n",
    "                    )\n",
    "\n",
    "                # Save the model if validation loss decreases\n",
    "                if valid_loss < valid_loss_min:\n",
    "                    # Save model\n",
    "                    torch.save(model.state_dict(), save_file_name)\n",
    "                    # Track improvement\n",
    "                    epochs_no_improve = 0\n",
    "                    valid_loss_min = valid_loss\n",
    "                    valid_best_acc = valid_acc\n",
    "                    best_epoch = epoch\n",
    "\n",
    "                # Otherwise increment count of epochs with no improvement\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    # Trigger early stopping\n",
    "                    if epochs_no_improve >= max_epochs_stop:\n",
    "                        print(\n",
    "                            f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "                        )\n",
    "                        total_time = timer() - overall_start\n",
    "                        print(\n",
    "                            f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
    "                        )\n",
    "\n",
    "                        # Load the best state dict\n",
    "                        model.load_state_dict(torch.load(save_file_name))\n",
    "                        # Attach the optimizer\n",
    "                        model.optimizer = optimizer\n",
    "\n",
    "                        # Format history\n",
    "                        history = pd.DataFrame(\n",
    "                            history,\n",
    "                            columns=[\n",
    "                                'train_loss', 'valid_loss', 'train_acc',\n",
    "                                'valid_acc'\n",
    "                            ])\n",
    "                        return model, history\n",
    "\n",
    "    # Attach the optimizer\n",
    "    model.optimizer = optimizer\n",
    "    # Record overall time and print out stats\n",
    "    total_time = timer() - overall_start\n",
    "    print(\n",
    "        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "    )\n",
    "    print(\n",
    "        f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\n",
    "    )\n",
    "    # Format history\n",
    "    history = pd.DataFrame(\n",
    "        history,\n",
    "        columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some of the model's hyperparameters\n",
    "model, history = train(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    dataloaders['train'],\n",
    "    dataloaders['val'],\n",
    "    save_file_name=save_file_name,\n",
    "    max_epochs_stop=15,\n",
    "    n_epochs=500,\n",
    "    print_every=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-uniform",
   "metadata": {},
   "source": [
    "# Train and validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for c in ['train_loss', 'valid_loss']:\n",
    "    plt.plot(\n",
    "        history[c], label=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Negative Log Likelihood')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.savefig('Training and Validation Losses test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-salon",
   "metadata": {},
   "source": [
    "# Train and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-coordinator",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for c in ['train_acc', 'valid_acc']:\n",
    "    plt.plot(\n",
    "        100 * history[c], label=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.savefig('Training and Validation Accuracy test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6571600",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for c in ['train_loss', 'valid_loss','train_acc', 'valid_acc']:\n",
    "    plt.plot(history[c], label=c)\n",
    "plt.legend()\n",
    "#plt.ylim(0, 1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Accuracy & Loss')\n",
    "plt.title('Combined Plot')\n",
    "plt.savefig('Combined Plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-webcam",
   "metadata": {},
   "source": [
    "# Save Model's weights and model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, path):\n",
    "    \"\"\"Save a PyTorch model checkpoint\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        model (PyTorch model): model to save\n",
    "        path (str): location to save model. Must start with `model_name-` and end in '.pth'\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        None, save the `model` to `path`\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model_name = path.split('-')[0]\n",
    "    assert (model_name in ['vgg16', 'resnet50'\n",
    "                           ]), \"Path must have the correct model name\"\n",
    "\n",
    "    # Basic details\n",
    "    checkpoint = {\n",
    "        'class_to_idx': model.class_to_idx,\n",
    "        'idx_to_class': model.idx_to_class,\n",
    "        'epochs': model.epochs,\n",
    "    }\n",
    "\n",
    "    # Extract the final classifier and the state dictionary\n",
    "    if model_name == 'vgg16':\n",
    "        # Check to see if model was parallelized\n",
    "        if multi_gpu:\n",
    "            checkpoint['classifier'] = model.module.classifier\n",
    "            checkpoint['state_dict'] = model.module.state_dict()\n",
    "        else:\n",
    "            checkpoint['classifier'] = model.classifier\n",
    "            checkpoint['state_dict'] = model.state_dict()\n",
    "\n",
    "    elif model_name == 'resnet50':\n",
    "        if multi_gpu:\n",
    "            checkpoint['fc'] = model.module.fc\n",
    "            checkpoint['state_dict'] = model.module.state_dict()\n",
    "        else:\n",
    "            checkpoint['fc'] = model.fc\n",
    "            checkpoint['state_dict'] = model.state_dict()\n",
    "\n",
    "    # Add the optimizer\n",
    "    checkpoint['optimizer'] = model.optimizer\n",
    "    checkpoint['optimizer_state_dict'] = model.optimizer.state_dict()\n",
    "\n",
    "    # Save the data to the path\n",
    "    torch.save(checkpoint, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(model, path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-thomas",
   "metadata": {},
   "source": [
    "# Load Checkpoint"
   ]
  },
  {
   "cell_type": "raw",
   "id": "rocky-calculator",
   "metadata": {},
   "source": [
    "Can start from this step if you already have a trained model saved along with the appropriate weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(path):\n",
    "    \"\"\"Load a PyTorch model checkpoint\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        path (str): saved model checkpoint. Must start with `model_name-` and end in '.pth'\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        None, save the `model` to `path`\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the model name\n",
    "    model_name = path.split('-')[0]\n",
    "    assert (model_name in ['vgg16', 'resnet50'\n",
    "                           ]), \"Path must have the correct model name\"\n",
    "\n",
    "    # Load in checkpoint\n",
    "    checkpoint = torch.load(path)\n",
    "\n",
    "    if model_name == 'vgg16':\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        # Make sure to set parameters as not trainable\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        model.classifier = checkpoint['classifier']\n",
    "\n",
    "    elif model_name == 'resnet50':\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        # Make sure to set parameters as not trainable\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        model.fc = checkpoint['fc']\n",
    "\n",
    "    # Load in the state dict\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f'{total_params:,} total parameters.')\n",
    "    total_trainable_params = sum(\n",
    "        p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'{total_trainable_params:,} total gradient parameters.')\n",
    "\n",
    "    # Move to gpu\n",
    "    if multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    if train_on_gpu:\n",
    "        model = model.to('cuda')\n",
    "\n",
    "    # Model basics\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    model.idx_to_class = checkpoint['idx_to_class']\n",
    "    model.epochs = checkpoint['epochs']\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = checkpoint['optimizer']\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer = load_checkpoint(path=checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-found",
   "metadata": {},
   "source": [
    "# Using the trained model for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path):\n",
    "    \"\"\"Process an image path into a PyTorch tensor\"\"\"\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "#     image = Image.open(image_path)\n",
    "    # Resize\n",
    "    img = image.resize((256, 256))\n",
    "\n",
    "    # Center crop\n",
    "    width = 256\n",
    "    height = 256\n",
    "    new_width = 224\n",
    "    new_height = 224\n",
    "\n",
    "    left = (width - new_width) / 2\n",
    "    top = (height - new_height) / 2\n",
    "    right = (width + new_width) / 2\n",
    "    bottom = (height + new_height) / 2\n",
    "    img = img.crop((left, top, right, bottom))\n",
    "\n",
    "    # Convert to numpy, transpose color dimension and normalize\n",
    "    img = np.array(img).transpose((2, 0, 1)) / 256\n",
    "\n",
    "    # Standardization\n",
    "    means = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n",
    "    stds = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n",
    "\n",
    "    img = img - means\n",
    "    img = img / stds\n",
    "\n",
    "    img_tensor = torch.Tensor(img)\n",
    "\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=6):\n",
    "    \"\"\"Make a prediction for an image using a trained model\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        image_path (str): filename of the image\n",
    "        model (PyTorch model): trained model for inference\n",
    "        topk (int): number of top predictions to return\n",
    "\n",
    "    Returns\n",
    "        \n",
    "    \"\"\"\n",
    "    real_class = image_path.split('/')[-2]\n",
    "\n",
    "    # Convert to pytorch tensor\n",
    "    img_tensor = process_image(image_path)\n",
    "\n",
    "    # Resize\n",
    "    if train_on_gpu:\n",
    "        img_tensor = img_tensor.view(1, 3, 224, 224).cuda()\n",
    "    else:\n",
    "        img_tensor = img_tensor.view(1, 3, 224, 224)\n",
    "\n",
    "    # Set to evaluation\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # Model outputs log probabilities\n",
    "        out = model(img_tensor)\n",
    "        ps = torch.exp(out)\n",
    "\n",
    "        # Find the topk predictions\n",
    "        topk, topclass = ps.topk(topk, dim=1)\n",
    "\n",
    "        # Extract the actual classes and probabilities\n",
    "        top_classes = [\n",
    "            model.idx_to_class[class_] for class_ in topclass.cpu().numpy()[0]\n",
    "        ]\n",
    "        top_p = topk.cpu().numpy()[0]\n",
    "\n",
    "        return img_tensor.cpu().squeeze(), top_p, top_classes, real_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 100\n",
    "\n",
    "\n",
    "def random_test_image():\n",
    "    \"\"\"Pick a random test image from the test directory\"\"\"\n",
    "    c = np.random.choice(categories)\n",
    "    root = testdir +\"/\"+ c + '/'\n",
    "    img_path = root + np.random.choice(os.listdir(root))\n",
    "    return img_path\n",
    "\n",
    "\n",
    "_ = imshow_tensor(process_image(random_test_image()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, top_p, top_classes, real_class = predict(random_test_image(), model,topk=6) # the number is the number of classes and predictions you want to show\n",
    "\n",
    "print('top_p, top_classes, real_class')\n",
    "top_p, top_classes, real_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-isaac",
   "metadata": {},
   "source": [
    "# Display the model's predictions on a random test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9f0d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "colors = []\n",
    "\n",
    "for i in range(6):\n",
    "    colors.append('#%06X' % randint(0, 0xFFFFFF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_prediction(image_path, model, topk):\n",
    "    \"\"\"Display image and preditions from model\"\"\"\n",
    "\n",
    "    # Get predictions\n",
    "    img, ps, classes, y_obs = predict(image_path, model, topk)\n",
    "    # Convert results to dataframe for plotting\n",
    "    result = pd.DataFrame({'p': ps}, index=classes)\n",
    "\n",
    "    # Show the image\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    ax, img = imshow_tensor(img, ax=ax)\n",
    "\n",
    "    # Set title to be the actual class\n",
    "    ax.set_title(y_obs, size=20)\n",
    "\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    # Plot a bar plot of predictions\n",
    "    result.sort_values('p')['p'].plot.barh(color=colors, edgecolor='k', ax=ax)\n",
    "    plt.xlabel('Predicted Probability')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Prediction draft_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_prediction(random_test_image(), model, topk=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-wagon",
   "metadata": {},
   "source": [
    "# Model's Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(6, )):\n",
    "    \"\"\"Compute the topk accuracy(s)\"\"\"\n",
    "    if train_on_gpu:\n",
    "        output = output.to('cuda')\n",
    "        target = target.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        # Find the predicted classes and transpose\n",
    "        _, pred = output.topk(k=maxk, dim=1, largest=True, sorted=True)\n",
    "        pred = pred.t()\n",
    "\n",
    "        # Determine predictions equal to the targets\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "\n",
    "        # For each k, find the percentage of correct\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size).item())\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "testiter = iter(dataloaders['test'])\n",
    "# Get a batch of testing images and labels\n",
    "features, targets = next(testiter)\n",
    "\n",
    "if train_on_gpu:\n",
    "    res = accuracy(model(features.to('cuda')), targets, topk=(1,))\n",
    "else:\n",
    "    res = accuracy(model(features), targets, topk=(1,))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-smell",
   "metadata": {},
   "source": [
    "# Function to Evaluate Model Over All Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, criterion, topk=(1, 6, )):\n",
    "    \"\"\"Measure the performance of a trained PyTorch model\n",
    "\n",
    "    Params\n",
    "    --------\n",
    "        model (PyTorch model): trained cnn for inference\n",
    "        test_loader (PyTorch DataLoader): test dataloader\n",
    "        topk (tuple of ints): accuracy to measure\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "        results (DataFrame): results for each category\n",
    "\n",
    "    \"\"\"\n",
    "    confusion_matrix = torch.zeros(n_classes, n_classes)\n",
    "    classes = []\n",
    "    losses = []\n",
    "    # Hold accuracy results\n",
    "    acc_results = np.zeros((len(test_loader.dataset), len(topk)))\n",
    "    i = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Testing loop\n",
    "        for data, targets in test_loader:\n",
    "\n",
    "            # Tensors to gpu\n",
    "            if train_on_gpu:\n",
    "                data, targets = data.to('cuda'), targets.to('cuda')\n",
    "\n",
    "            # Raw model output\n",
    "            out = model(data)\n",
    "            _, predscm = torch.max(out, 1)\n",
    "            for t, p in zip(targets.view(-1), predscm.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "            \n",
    "            # Iterate through each example\n",
    "            for pred, true in zip(out, targets):\n",
    "                # Find topk accuracy\n",
    "                acc_results[i, :] = accuracy(\n",
    "                    pred.unsqueeze(0), true.unsqueeze(0), topk)\n",
    "                classes.append(model.idx_to_class[true.item()])\n",
    "                # Calculate the loss\n",
    "                loss = criterion(pred.view(1, n_classes), true.view(1))\n",
    "                losses.append(loss.item())\n",
    "                i += 1\n",
    "\n",
    "    # Send results to a dataframe and calculate average across classes\n",
    "    results = pd.DataFrame(acc_results, columns=[f'top{i}' for i in topk])\n",
    "    results['class'] = classes\n",
    "    results['loss'] = losses\n",
    "    results = results.groupby(classes).mean()\n",
    "\n",
    "    return results.reset_index().rename(columns={'index': 'class'}),confusion_matrix\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "# Evaluate the model on all the training data\n",
    "results,confusion_matrix = evaluate(model, dataloaders['test'], criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.OrRd):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else '.0f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(f'outputs/confusion_matrix test.png')\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames = [model.idx_to_class[i] for i in range(0,n_classes)]\n",
    "plt.figure(figsize=(18,18))\n",
    "plt = plot_confusion_matrix(confusion_matrix, classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_as_dataframe(cm):\n",
    "    cm = pd.DataFrame(cm)\n",
    "    cm.columns = classnames\n",
    "    cm.index = classnames\n",
    "    cm = cm.reset_index()\n",
    "    return cm\n",
    "\n",
    "cm_as_dataframe(confusion_matrix.cpu().numpy()).to_csv(f'outputs/confmat.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-sailing",
   "metadata": {},
   "source": [
    "# Test Accuracy : Overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Overall Accuracy:{confusion_matrix.diag().sum()/confusion_matrix.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.merge(cnt_df,left_on='class',right_on='cat')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv file\n",
    "results.to_csv(f'outputs/test_accuracy.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-institute",
   "metadata": {},
   "source": [
    "# Check Class (Specific Structure Test Folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_category(model, category, n=6):\n",
    "    \"\"\"Display predictions for a category    \n",
    "    \"\"\"\n",
    "    category_results = results.loc[results['class'] == category]\n",
    "    #print(category_results.iloc[:, :10], '/n')\n",
    "\n",
    "    images = np.random.choice(\n",
    "        os.listdir(testdir + \"/\"+category + '/'), size=n, replace=False)\n",
    "\n",
    "    for img in images:\n",
    "        display_prediction(testdir +\"/\"+ category + '/' + img, model, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-nudist",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_category(model, 'Class 1', n=5) # n represents the number of test images the model will run predictions on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-peninsula",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_category(model, 'Class 2', n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e00d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
